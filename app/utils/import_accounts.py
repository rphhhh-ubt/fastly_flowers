# app/utils/import_accounts.py

import os
import re
import json
import zipfile
import asyncio
from aiogram.types import BufferedInputFile
from app.db import (
    create_account_with_metadata,
    is_account_exists,
    get_available_api_key,
    increment_api_key_usage,
    proxy_exists,
    save_proxy,
    ensure_accounts_metadata_columns,
    account_exists_by_session,
    get_account_by_session_string, 
    merge_account_metadata_by_session,
)
from app.db_bootstrap import bootstrap_accounts_privileges  # <<< –¥–æ–±–∞–≤–∏–ª–∏
from telethon import TelegramClient
from telethon.sessions import SQLiteSession, StringSession
import socks

print("[IMPORT ACCOUNTS] loaded from:", __file__, flush=True)



def _find_json_for_session(session_file: str, temp_dir: str) -> str | None:
    """
    –ü—ã—Ç–∞–µ—Ç—Å—è —Å–æ–ø–æ—Å—Ç–∞–≤–∏—Ç—å .session —Å .json:
    - <stem>.json
    - <stem –±–µ–∑ —Å—É—Ñ—Ñ–∏–∫—Å–æ–≤ _telethon/_tdesktop/_td/_tdata>.json
    - <—á–∞—Å—Ç—å –¥–æ –ø–µ—Ä–≤–æ–≥–æ _>.json
    - <—á–∏—Å–ª–æ–≤–æ–π –ø—Ä–µ—Ñ–∏–∫—Å>.json (–µ—Å–ª–∏ –µ—Å—Ç—å)
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –ø–µ—Ä–≤—ã–π –Ω–∞–π–¥–µ–Ω–Ω—ã–π –ø—É—Ç—å –∏–ª–∏ None.
    """
    stem = session_file[:-8]  # —É–±—Ä–∞—Ç—å ".session"
    candidates = [os.path.join(temp_dir, stem + ".json")]

    # —É–±—Ä–∞—Ç—å —Ä–∞—Å–ø—Ä–æ—Å—Ç—Ä–∞–Ω—ë–Ω–Ω—ã–µ —Å—É—Ñ—Ñ–∏–∫—Å—ã
    for suf in ("_telethon", "_tdesktop", "_td", "_tdata"):
        if stem.endswith(suf):
            candidates.append(os.path.join(temp_dir, stem[:-len(suf)] + ".json"))

    # –¥–æ –ø–µ—Ä–≤–æ–≥–æ –ø–æ–¥—á—ë—Ä–∫–∏–≤–∞–Ω–∏—è
    if "_" in stem:
        candidates.append(os.path.join(temp_dir, stem.split("_", 1)[0] + ".json"))

    # —á–∏—Å–ª–æ–≤–æ–π –ø—Ä–µ—Ñ–∏–∫—Å
    m = re.match(r"(\d{6,})", stem)
    if m:
        candidates.append(os.path.join(temp_dir, m.group(1) + ".json"))

    # —É–¥–∞–ª–∏—Ç—å –¥—É–±–ª–∏–∫–∞—Ç—ã, –≤–µ—Ä–Ω—É—Ç—å –ø–µ—Ä–≤—ã–π —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π
    seen = set()
    for p in candidates:
        if p in seen:
            continue
        seen.add(p)
        if os.path.exists(p):
            return p
    return None


# --- helpers for JSON meta parsing and logging ---
def _safe_int(v):
    try:
        if v is None or v == "":
            return None
        return int(v)
    except Exception:
        return None

def _safe_bool(v):
    if isinstance(v, bool):
        return v
    if isinstance(v, (int, float)):
        return bool(v)
    if isinstance(v, str):
        s = v.strip().lower()
        if s in ("true", "1", "yes", "y", "on"):
            return True
        if s in ("false", "0", "no", "n", "off"):
            return False
    return False

def _safe_str(v):
    if v is None:
        return None
    s = str(v).strip()
    return s or None

def _load_json_metadata(json_path: str) -> dict:
    try:
        with open(json_path, "r", encoding="utf-8") as f:
            raw = f.read().strip()
        if not raw:
            return {}
        data = json.loads(raw)
        if isinstance(data, str):
            data = json.loads(data)
        if not isinstance(data, dict):
            return {}
        meta = {
            "device_model":     _safe_str(data.get("device")),
            "system_version":   _safe_str(data.get("sdk")),
            "app_version":      _safe_str(data.get("app_version")),
            "lang_code":        _safe_str(data.get("lang_code")),
            "system_lang_code": _safe_str(data.get("system_lang_code")),
            "is_premium":       _safe_bool(data.get("is_premium")),
            "register_time":    _safe_int(data.get("register_time")),
        }
        cleaned = {}
        for k, v in meta.items():
            if k == "is_premium":
                cleaned[k] = bool(v)
            elif v is not None:
                cleaned[k] = v
        return cleaned
    except Exception as e:
        print(f"[IMPORT] meta parse error: {e}", flush=True)
        return {}

def _print_meta_loaded(index: int, meta: dict):
    if not meta:
        print(f"[IMPORT] [{index}] meta: none", flush=True)
        return
    order = ["device_model", "system_version", "app_version", "lang_code", "system_lang_code", "is_premium", "register_time"]
    parts = []
    for k in order:
        if k in meta:
            v = meta[k]
            parts.append(f"{k}={v}{' (unix)' if k=='register_time' and v is not None else ''}")
    print(f"[IMPORT] [{index}] meta: {', '.join(parts) if parts else 'none'}", flush=True)


async def _extract_zip(zip_path: str, temp_dir: str):
    def _extract():
        with zipfile.ZipFile(zip_path, 'r') as z:
            z.extractall(temp_dir)
    await asyncio.to_thread(_extract)

def _read_proxies_file(path: str) -> list[str]:
    if not os.path.exists(path):
        return []
    with open(path, "r", encoding="utf-8", errors="ignore") as f:
        return [line.strip() for line in f if line.strip()]

def _sqlite_file_to_string_session(session_path: str) -> str:
    base = session_path[:-8] if session_path.endswith(".session") else session_path
    sqlite_session = SQLiteSession(base)
    return StringSession.save(sqlite_session)

def _make_proxy_tuple(host, port, user, pwd):
    return (socks.SOCKS5, host, int(port), True, user or None, pwd or None)


async def _import_one(index: int, session_file: str, proxy_line: str, temp_dir: str, log, counters):
    session_path = os.path.join(temp_dir, session_file)
    json_path = _find_json_for_session(session_file, temp_dir)
    print(f"[IMPORT] [{index}] session={session_file}, json={'found: ' + os.path.basename(json_path) if json_path else 'none'}", flush=True)

    
    # 1) proxy
    try:
        parts = (proxy_line or "").split(":")
        phost = parts[0]
        pport = int(parts[1])
        puser = parts[2] if len(parts) > 2 and parts[2] else None
        ppwd  = parts[3] if len(parts) > 3 and parts[3] else None
    except Exception as e:
        msg = f"[‚ùå] {session_file} ‚Äî –Ω–µ–≤–µ—Ä–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç –ø—Ä–æ–∫—Å–∏ '{proxy_line}': {e}"
        print(f"[IMPORT] {msg}", flush=True); counters["fail"] += 1; log.append(msg); return

    # 2) api key
    api_key = get_available_api_key()
    if not api_key:
        msg = f"[‚ùå] {session_file} ‚Äî –Ω–µ—Ç —Å–≤–æ–±–æ–¥–Ω—ã—Ö API-–∫–ª—é—á–µ–π"
        print(f"[IMPORT] {msg}", flush=True); counters["fail"] += 1; log.append(msg); return

    # 3) .session ‚Üí StringSession
    try:
        string_sess = _sqlite_file_to_string_session(session_path)
        print(f"[IMPORT] [{index}] StringSession –ø–æ–ª—É—á–µ–Ω ({len(string_sess)} —Å–∏–º–≤–æ–ª–æ–≤)", flush=True)
    except Exception as e:
        msg = f"[‚ùå] {session_file} ‚Äî –Ω–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ—á–∏—Ç–∞—Ç—å .session: {e}"
        print(f"[IMPORT] {msg}", flush=True); counters["fail"] += 1; log.append(msg); return
    

    # === –ù–û–í–û–ï: –µ—Å–ª–∏ —Ç–∞–∫–æ–π session —É–∂–µ –µ—Å—Ç—å ‚Äî ¬´–¥–æ–∫–ª–µ–∏–º¬ª –ú–ï–¢–ê –∏–∑ –Ω–∞–π–¥–µ–Ω–Ω–æ–≥–æ JSON –∏ –≤—ã–π–¥–µ–º
    if account_exists_by_session(string_sess):
        if json_path:
            meta = _load_json_metadata(json_path) or {}
            try:
                acc = get_account_by_session_string(string_sess) or {}
                if not meta:
                    msg = f"[‚ÑπÔ∏è] –∞–∫–∫–∞—É–Ω—Ç ID {acc.get('id','?')}: JSON –Ω–∞–π–¥–µ–Ω, –Ω–æ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö –Ω–µ—Ç ‚Äî –æ–±–Ω–æ–≤–ª—è—Ç—å –Ω–µ—á–µ–≥–æ"
                    counters["skipped"] += 1
                else:
                    affected = merge_account_metadata_by_session(string_sess, meta)
                    if affected:
                        msg = f"[‚ÑπÔ∏è] –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –¥–ª—è –∞–∫–∫–∞—É–Ω—Ç–∞ ID {acc.get('id','?')} –æ–±–Ω–æ–≤–ª–µ–Ω—ã (—Ç–æ–ª—å–∫–æ –ø—É—Å—Ç—ã–µ –ø–æ–ª—è)"
                    else:
                        msg = f"[‚ÑπÔ∏è] –∞–∫–∫–∞—É–Ω—Ç ID {acc.get('id','?')} —É–∂–µ —Å–æ–¥–µ—Ä–∂–∏—Ç –≤—Å–µ –ø–æ–ª—è, –æ–±–Ω–æ–≤–ª—è—Ç—å –Ω–µ—á–µ–≥–æ"
                    counters["updated"] += 1   # ‚Üê –∞ –Ω–µ fail
            except Exception as e:
                msg = f"[‚ö†Ô∏è] –Ω–µ —É–¥–∞–ª–æ—Å—å –æ–±–Ω–æ–≤–∏—Ç—å –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –¥–ª—è –¥—É–±–ª–∏–∫–∞—Ç–∞: {e}"
                counters["fail"] += 1         # ‚Üê —ç—Ç–æ —É–∂–µ –æ—à–∏–±–∫–∞
        else:
            msg = f"[‚ÑπÔ∏è] –Ω–∞–π–¥–µ–Ω –¥—É–±–ª–∏–∫–∞—Ç –ø–æ session_string, –ø–æ–¥—Ö–æ–¥—è—â–∏–π JSON –Ω–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω ‚Äî –ø—Ä–æ–ø—É—Å–∫"
            counters["skipped"] += 1          # ‚Üê –ø—Ä–æ–ø—É—Å–∫, –Ω–µ –æ—à–∏–±–∫–∞

        log.append(msg)
        print(f"[IMPORT] {msg}", flush=True)
        return

    
    
    proxy_tuple = _make_proxy_tuple(phost, pport, puser, ppwd)
    print(f"[IMPORT] [{index}] proxy={phost}:{pport} user={'yes' if puser else 'no'}", flush=True)

    # 4) connect & validate
    client = None
    try:
        client = TelegramClient(
            StringSession(string_sess),
            api_key["api_id"],
            api_key["api_hash"],
            proxy=proxy_tuple,
            connection_retries=1,
            request_retries=1,
            timeout=20,
        )
        await client.connect()
        print(f"[IMPORT] [{index}] connected", flush=True)
        increment_api_key_usage(api_key["id"])

        me = await client.get_me()
        if not me:
            raise Exception("–°–µ—Å—Å–∏—è –Ω–µ –∞–≤—Ç–æ—Ä–∏–∑–æ–≤–∞–Ω–∞ (get_me –≤–µ—Ä–Ω—É–ª None)")

        phone = getattr(me, "phone", None)
        username = getattr(me, "username", None)
        who = phone or username or session_file
        print(f"[IMPORT] [{index}] me: phone={phone} username={username}", flush=True)

        if is_account_exists(phone, username):
            msg = f"[‚ÑπÔ∏è] {who} ‚Äî —É–∂–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç (–ø–æ phone/username), –ø—Ä–æ–ø—É—Å–∫"
            counters["fail"] += 1; log.append(msg); print(f"[IMPORT] {msg}", flush=True); return

        # 5) save proxy (if new)
        if phost and pport and not proxy_exists(phost, pport, puser, ppwd):
            save_proxy(phost, pport, puser, ppwd)

        # 6) meta from JSON
        meta = _load_json_metadata(json_path) if json_path else {}
        _print_meta_loaded(index, meta)


        # 7) save account
        create_account_with_metadata(
            session_string=string_sess,
            proxy_type="socks5",
            proxy_host=phost,
            proxy_port=pport,
            proxy_username=puser,
            proxy_password=ppwd,
            phone=phone,
            username=username,
            device_model=meta.get("device_model"),
            system_version=meta.get("system_version"),
            app_version=meta.get("app_version"),
            lang_code=meta.get("lang_code"),
            system_lang_code=meta.get("system_lang_code"),
            is_premium=bool(meta.get("is_premium", False)),
            register_time=meta.get("register_time"),
        )

        msg = f"[‚úÖ] {who} ‚Äî –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω"
        counters["ok"] += 1; log.append(msg); print(f"[IMPORT] {msg}", flush=True)

    except Exception as e:
        msg = f"[‚ùå] {session_file} ‚Äî –æ—à–∏–±–∫–∞: {e}"
        counters["fail"] += 1; log.append(msg); print(f"[IMPORT] {msg}", flush=True)
    finally:
        if client:
            try: await client.disconnect()
            except Exception: pass


async def import_accounts_from_zip(message, zip_path, temp_dir):
    print(f"[IMPORT] start zip_path={zip_path} temp_dir={temp_dir}", flush=True)

    # 0) –ê–≤—Ç–æ-ensure + –∞–≤—Ç–æ-BOOTSTRAP –ø—Ä–∏ –æ—à–∏–±–∫–µ –ø—Ä–∞–≤
    try:
        ensure_accounts_metadata_columns()
        print("[IMPORT] ensure_accounts_metadata_columns: OK", flush=True)
    except Exception as e:
        print(f"[IMPORT] ensure failed: {e} ‚Äî trying bootstrap...", flush=True)
        res = bootstrap_accounts_privileges()
        print(f"[BOOTSTRAP] result: {res}", flush=True)
        # –ø–æ–≤—Ç–æ—Ä–∏–º ensure
        try:
            ensure_accounts_metadata_columns()
            print("[IMPORT] ensure_accounts_metadata_columns after bootstrap: OK", flush=True)
        except Exception as e2:
            print(f"[IMPORT] ‚ùå ensure failed again: {e2}", flush=True)
            await message.answer("‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–¥–≥–æ—Ç–æ–≤–∫–µ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö.")
            return

    log, counters = [], {"ok": 0, "updated": 0, "skipped": 0, "fail": 0}
    try:
        # 1) unzip
        await _extract_zip(zip_path, temp_dir)
        print("[IMPORT] zip extracted", flush=True)

        # 2) list .session only
        sessions = [f for f in os.listdir(temp_dir) if f.endswith(".session")]
        sessions.sort()
        proxies_path = os.path.join(temp_dir, "proxies.txt")
        proxy_lines = _read_proxies_file(proxies_path)
        print(f"[IMPORT] found sessions: {len(sessions)}; proxies lines: {len(proxy_lines)} (json files not counted)", flush=True)

        if len(proxy_lines) != len(sessions):
            await message.answer("‚ùå –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–æ–∫—Å–∏ –Ω–µ —Å–æ–≤–ø–∞–¥–∞–µ—Ç —Å –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ–º —Å–µ—Å—Å–∏–π.")
            return

        # 3) import
        for i, sess in enumerate(sessions, 1):
            await _import_one(i, sess, proxy_lines[i - 1], temp_dir, log, counters)

        # 4) send log
        log_text = (
            "\n".join(log) +
            f"\n\n–ò—Ç–æ–≥–æ:\n"
            f"‚úÖ –ò–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–æ: {counters['ok']}\n"
            f"‚ôªÔ∏è –û–±–Ω–æ–≤–ª–µ–Ω–æ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö: {counters['updated']}\n"
            f"‚è≠Ô∏è –ü—Ä–æ–ø—É—â–µ–Ω–æ: {counters['skipped']}\n"
            f"‚ùå –û—à–∏–±–æ–∫: {counters['fail']}"
        )
        log_file_path = os.path.join(temp_dir, "import_log.txt")
        with open(log_file_path, "w", encoding="utf-8") as f:
            f.write(log_text)

        with open(log_file_path, "rb") as f:
            await message.answer_document(
                document=BufferedInputFile(f.read(), filename="import_log.txt"),
                caption="üìÑ –õ–æ–≥ –∏–º–ø–æ—Ä—Ç–∞ –∞–∫–∫–∞—É–Ω—Ç–æ–≤"
            )

    except Exception as e:
        print(f"‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –≤ import_accounts_from_zip: {e}", flush=True)
        import traceback; traceback.print_exc()
        await message.answer("‚ùå –ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –∞—Ä—Ö–∏–≤–∞.")
    finally:
        # cleanup
        try:
            if os.path.exists(zip_path): os.remove(zip_path)
            if os.path.exists(temp_dir):
                for f in os.listdir(temp_dir):
                    try: os.remove(os.path.join(temp_dir, f))
                    except Exception: pass
                try: os.rmdir(temp_dir)
                except Exception: pass
        except Exception:
            pass
